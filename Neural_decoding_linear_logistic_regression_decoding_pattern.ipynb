{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn\n",
    "# pip install xgboost\n",
    "# pip install keras\n",
    "# pip install sklearn\n",
    "# pip install pandas\n",
    "# pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(pd.read_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_x = pd.read_excel('Research data sample.xlsx', sheet_name = 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_excel('Research data.xlsx', sheet_name = 'Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  Column2  Column3  Column4  Column5  Column6  Column7  Column8  \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   Column9  Column10  ...  Column12  Column13  Column14  Column15  Column16  \\\n",
       "0        0         0  ...         0         0         0         0         0   \n",
       "1        0         0  ...         0         0         0         0         0   \n",
       "\n",
       "   Column17  Column18  Column19  Column20  Column21  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         1  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Column1', 'Column2', 'Column3', 'Column4', 'Column5', 'Column6',\n",
       "       'Column7', 'Column8', 'Column9', 'Column10', 'Column11', 'Column12',\n",
       "       'Column13', 'Column14', 'Column15', 'Column16', 'Column17', 'Column18',\n",
       "       'Column19', 'Column20', 'Column21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_y = pd.read_excel('Research data sample.xlsx', sheet_name = 'Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.read_excel('Research data.xlsx', sheet_name = 'Sheet3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1\n",
       "0   66.193\n",
       "1   66.193"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_y.rename(columns={'Column1': 'Position'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Position\n",
       "0    66.193\n",
       "1    66.193"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_x\n",
    "df_all['Position'] = df_y['Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.to_csv('all-combined-data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729633"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_x[0:500000]\n",
    "test_x = df_x[600000:]\n",
    "train_y = df_y[0:500000]\n",
    "test_y = df_y[600000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = df_x[500000:600000]\n",
    "val_y = df_y[500000:600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_x, test_x, train_y, test_y = train_test_split(df_x, df_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  Column2  Column3  Column4  Column5  Column6  Column7  Column8  \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   Column9  Column10  ...  Column13  Column14  Column15  Column16  Column17  \\\n",
       "0        0         0  ...         0         0         0         0         0   \n",
       "1        0         0  ...         0         0         0         0         0   \n",
       "\n",
       "   Column18  Column19  Column20  Column21  Position  \n",
       "0         0         0         0         0    66.193  \n",
       "1         0         0         0         1    66.193  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129633"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Simple Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Followed this blogpost: https://aigeekprogrammer.com/binary-classification-using-logistic-regression-and-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ayush\\Anaconda3\\envs\\event-type\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 22)                44        \n",
      "=================================================================\n",
      "Total params: 44\n",
      "Trainable params: 44\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LR_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "LR_model.add(Dense(train_x.shape[1], kernel_initializer='normal',input_dim = train_y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the network :\n",
    "LR_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "LR_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a folder call \"lr_models\" to save your model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'lr_models_decoding/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.callbacks.ModelCheckpoint at 0x224828cf9e8>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 22)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?NN_model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ayush\\Anaconda3\\envs\\event-type\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 500000 samples, validate on 100000 samples\n",
      "Epoch 1/50\n",
      "500000/500000 [==============================] - 20s 40us/step - loss: 8.2197 - mean_absolute_error: 8.2197 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.96749, saving model to lr_models_decoding/Weights-001--7.96749.hdf5\n",
      "Epoch 2/50\n",
      "500000/500000 [==============================] - 18s 37us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-002--7.96749.hdf5\n",
      "Epoch 3/50\n",
      "500000/500000 [==============================] - 20s 40us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00003: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-003--7.96749.hdf5\n",
      "Epoch 4/50\n",
      "500000/500000 [==============================] - 21s 41us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-004--7.96749.hdf5\n",
      "Epoch 5/50\n",
      "500000/500000 [==============================] - 23s 46us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00005: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-005--7.96749.hdf5\n",
      "Epoch 6/50\n",
      "500000/500000 [==============================] - 28s 56us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00006: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-006--7.96749.hdf5\n",
      "Epoch 7/50\n",
      "500000/500000 [==============================] - 40s 80us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00007: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-007--7.96749.hdf5\n",
      "Epoch 8/50\n",
      "500000/500000 [==============================] - 38s 76us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00008: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-008--7.96749.hdf5\n",
      "Epoch 9/50\n",
      "500000/500000 [==============================] - 31s 62us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00009: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-009--7.96749.hdf5\n",
      "Epoch 10/50\n",
      "500000/500000 [==============================] - 47s 93us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00010: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-010--7.96749.hdf5\n",
      "Epoch 11/50\n",
      "500000/500000 [==============================] - 50s 100us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00011: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-011--7.96749.hdf5\n",
      "Epoch 12/50\n",
      "500000/500000 [==============================] - 49s 98us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00012: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-012--7.96749.hdf5\n",
      "Epoch 13/50\n",
      "500000/500000 [==============================] - 42s 84us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00013: val_loss improved from 7.96749 to 7.96749, saving model to lr_models_decoding/Weights-013--7.96749.hdf5\n",
      "Epoch 14/50\n",
      "500000/500000 [==============================] - 42s 84us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00014: val_loss improved from 7.96749 to 7.96748, saving model to lr_models_decoding/Weights-014--7.96748.hdf5\n",
      "Epoch 15/50\n",
      "500000/500000 [==============================] - 29s 57us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 7.96748\n",
      "Epoch 16/50\n",
      "500000/500000 [==============================] - 27s 54us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00016: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-016--7.96748.hdf5\n",
      "Epoch 17/50\n",
      "500000/500000 [==============================] - 30s 59us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00017: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-017--7.96748.hdf5\n",
      "Epoch 18/50\n",
      "500000/500000 [==============================] - 26s 52us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00018: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-018--7.96748.hdf5\n",
      "Epoch 19/50\n",
      "500000/500000 [==============================] - 29s 59us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00019: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-019--7.96748.hdf5\n",
      "Epoch 20/50\n",
      "500000/500000 [==============================] - 30s 60us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 7.96748\n",
      "Epoch 21/50\n",
      "500000/500000 [==============================] - 26s 51us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00021: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-021--7.96748.hdf5\n",
      "Epoch 22/50\n",
      "500000/500000 [==============================] - 37s 74us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 7.96748\n",
      "Epoch 23/50\n",
      "500000/500000 [==============================] - 21s 42us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 7.96748\n",
      "Epoch 24/50\n",
      "500000/500000 [==============================] - 24s 48us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00024: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-024--7.96748.hdf5\n",
      "Epoch 25/50\n",
      "500000/500000 [==============================] - 27s 54us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00025: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-025--7.96748.hdf5\n",
      "Epoch 26/50\n",
      "500000/500000 [==============================] - 19s 38us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 7.96748\n",
      "Epoch 27/50\n",
      "500000/500000 [==============================] - 22s 44us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00027: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-027--7.96748.hdf5\n",
      "Epoch 28/50\n",
      "500000/500000 [==============================] - 21s 42us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00028: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-028--7.96748.hdf5\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 25s 50us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00029: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-029--7.96748.hdf5\n",
      "Epoch 30/50\n",
      "500000/500000 [==============================] - 26s 52us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00030: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-030--7.96748.hdf5\n",
      "Epoch 31/50\n",
      "500000/500000 [==============================] - 32s 64us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00031: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-031--7.96748.hdf5\n",
      "Epoch 32/50\n",
      "500000/500000 [==============================] - 22s 43us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00032: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-032--7.96748.hdf5\n",
      "Epoch 33/50\n",
      "500000/500000 [==============================] - 24s 47us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00033: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-033--7.96748.hdf5\n",
      "Epoch 34/50\n",
      "500000/500000 [==============================] - 24s 47us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00034: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-034--7.96748.hdf5\n",
      "Epoch 35/50\n",
      "500000/500000 [==============================] - 22s 45us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 7.96748\n",
      "Epoch 36/50\n",
      "500000/500000 [==============================] - 22s 44us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 7.96748\n",
      "Epoch 37/50\n",
      "500000/500000 [==============================] - 23s 46us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00037: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-037--7.96748.hdf5\n",
      "Epoch 38/50\n",
      "500000/500000 [==============================] - 20s 40us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 7.96748\n",
      "Epoch 39/50\n",
      "500000/500000 [==============================] - 23s 47us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00039: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-039--7.96748.hdf5\n",
      "Epoch 40/50\n",
      "500000/500000 [==============================] - 22s 44us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00040: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-040--7.96748.hdf5\n",
      "Epoch 41/50\n",
      "500000/500000 [==============================] - 18s 35us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00041: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-041--7.96748.hdf5\n",
      "Epoch 42/50\n",
      "500000/500000 [==============================] - 20s 40us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 7.96748\n",
      "Epoch 43/50\n",
      "500000/500000 [==============================] - 20s 41us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00043: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-043--7.96748.hdf5\n",
      "Epoch 44/50\n",
      "500000/500000 [==============================] - 18s 37us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00044: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-044--7.96748.hdf5\n",
      "Epoch 45/50\n",
      "500000/500000 [==============================] - 17s 35us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00045: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-045--7.96748.hdf5\n",
      "Epoch 46/50\n",
      "500000/500000 [==============================] - 19s 38us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00046: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-046--7.96748.hdf5\n",
      "Epoch 47/50\n",
      "500000/500000 [==============================] - 23s 46us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 7.96748\n",
      "Epoch 48/50\n",
      "500000/500000 [==============================] - 22s 44us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00048: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-048--7.96748.hdf5\n",
      "Epoch 49/50\n",
      "500000/500000 [==============================] - 18s 35us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00049: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-049--7.96748.hdf5\n",
      "Epoch 50/50\n",
      "500000/500000 [==============================] - 18s 35us/step - loss: 8.2184 - mean_absolute_error: 8.2184 - val_loss: 7.9675 - val_mean_absolute_error: 7.9675\n",
      "\n",
      "Epoch 00050: val_loss improved from 7.96748 to 7.96748, saving model to lr_models_decoding/Weights-050--7.96748.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224a9fa5710>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model.fit(target, train, epochs=50, batch_size=64, validation_data = (val_y.to_numpy(), val_x.to_numpy()), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wights_file = 'lr_models_decoding/Weights-050--7.96748.hdf5' # choose the best checkpoint \n",
    "LR_model.load_weights(wights_file) # load it\n",
    "LR_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([215.35])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = LR_model.predict(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will judge our model on Mean Absolute Error Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network validation MAE =  7.469172929561964\n"
     ]
    }
   ],
   "source": [
    "MAE = mean_absolute_error(test , predictions)\n",
    "print('Deep Neural Network validation MAE = ', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
